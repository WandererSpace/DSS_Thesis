{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef6e92f-2ba4-47e5-88d5-a463f0b84484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable 'ghq12_distress' created (Threshold: 4).\n",
      "Target distribution:\n",
      "| ghq12_distress   | count   |\n",
      "|:-----------------|:--------|\n",
      "| 0                | 26779   |\n",
      "| 1                | 7335    |\n",
      "\n",
      "Model 1 (Baseline) feature count: 48\n",
      "Model 2 (Augmented) feature count: 251\n",
      "\n",
      "--- Training Model 1 (Baseline: Core Unemp + Core Edu + Demographics) ---\n",
      "Model 1 ROC AUC Score: 0.7040\n",
      "Classification Report M1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77      5356\n",
      "           1       0.35      0.59      0.44      1467\n",
      "\n",
      "    accuracy                           0.67      6823\n",
      "   macro avg       0.60      0.64      0.60      6823\n",
      "weighted avg       0.75      0.67      0.70      6823\n",
      "\n",
      "\n",
      "--- Training Model 2 (Augmented: All Features) ---\n",
      "Model 2 ROC AUC Score: 0.7322\n",
      "Classification Report M2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.73      0.79      5356\n",
      "           1       0.38      0.61      0.47      1467\n",
      "\n",
      "    accuracy                           0.70      6823\n",
      "   macro avg       0.62      0.67      0.63      6823\n",
      "weighted avg       0.76      0.70      0.72      6823\n",
      "\n",
      "\n",
      "--- Model Comparison Summary (GHQ-12 Distress Classification) ---\n",
      "| Model               | Features   | ROC AUC Score   |\n",
      "|:--------------------|:-----------|:----------------|\n",
      "| Model 1 (Baseline)  | 48         | 0.7040          |\n",
      "| Model 2 (Augmented) | 251        | 0.7322          |\n",
      "\n",
      "Top 10 Most Influential Features (Coefficients) for Model 1:\n",
      "|                               | 0          |\n",
      "|:------------------------------|:-----------|\n",
      "| has_disability                | 0.522359   |\n",
      "| financial_difficulty          | 0.417484   |\n",
      "| female                        | 0.197914   |\n",
      "| is_currently_unemployed       | 0.0941193  |\n",
      "| is_urban                      | 0.0511747  |\n",
      "| marstat_final_2.1             | -0.0276555 |\n",
      "| marstat_final_2               | -0.0276555 |\n",
      "| education_level_Low_Education | -0.0410742 |\n",
      "| n_hhsize                      | -0.060951  |\n",
      "| n_age_dv                      | -0.357279  |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# --- 0. Define File Path ---\n",
    "file_path = \"/Users/wanderer/Thesis/ModelProject/Processed_Data/n_indresp_FINAL_FEATURES_OPTIMIZED.csv\"\n",
    "TARGET_CONT_COL = 'ghq12_continuous_score'\n",
    "TARGET_BIN_COL = 'ghq12_distress'\n",
    "GHQ12_THRESHOLD = 4\n",
    "\n",
    "# --- 1. Load and Clean Column Names ---\n",
    "\n",
    "def make_columns_unique(df):\n",
    "    \"\"\"Makes column names unique by appending a counter to duplicates.\"\"\"\n",
    "    cols = df.columns\n",
    "    seen = {}\n",
    "    new_cols = []\n",
    "    for item in cols:\n",
    "        original_name = item\n",
    "        count = seen.get(original_name, 0)\n",
    "        if count == 0:\n",
    "            new_cols.append(original_name)\n",
    "        else:\n",
    "            new_cols.append(f\"{original_name}_{count}\")\n",
    "        seen[original_name] = count + 1\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = make_columns_unique(df)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at the specified path: {file_path}\")\n",
    "    raise\n",
    "\n",
    "# --- 2. Target Transformation and Filtering ---\n",
    "# Drop rows where GHQ-12 score is missing or negative (inapplicable)\n",
    "df = df.dropna(subset=[TARGET_CONT_COL]).copy()\n",
    "df = df[df[TARGET_CONT_COL] >= 0].copy()\n",
    "\n",
    "# Create the binary target variable\n",
    "# 1: Distress (GHQ-12 >= 4)\n",
    "# 0: No Distress (GHQ-12 < 4)\n",
    "df[TARGET_BIN_COL] = (df[TARGET_CONT_COL] >= GHQ12_THRESHOLD).astype(int)\n",
    "\n",
    "print(f\"Target variable '{TARGET_BIN_COL}' created (Threshold: {GHQ12_THRESHOLD}).\")\n",
    "print(\"Target distribution:\")\n",
    "print(df[TARGET_BIN_COL].value_counts().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# --- 3. Feature Preparation (Imputation and Encoding) ---\n",
    "\n",
    "# Define columns to be dropped\n",
    "drop_cols = ['pidp', 'mental_health_status', TARGET_CONT_COL, TARGET_BIN_COL, 'has_mh_issue']\n",
    "X = df.drop(columns=[col for col in drop_cols if col in df.columns], errors='ignore')\n",
    "y = df[TARGET_BIN_COL]\n",
    "\n",
    "# Identify column types\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "\n",
    "# Impute unemployment/job chance features with 0\n",
    "unemp_impute_zero = ['last_unemployment_duration_months', 'subjective_job_chance_likely', 'unemployment_spells_count']\n",
    "for col in unemp_impute_zero:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].fillna(0)\n",
    "\n",
    "# Impute other numerical features with the median\n",
    "numerical_to_impute = [col for col in numerical_cols if col not in unemp_impute_zero]\n",
    "for col in numerical_to_impute:\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# Impute categorical features with the mode\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].fillna(X[col].mode()[0])\n",
    "\n",
    "# Perform One-Hot Encoding on all categorical features\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "\n",
    "# --- 4. Train-Test Split (80/20) ---\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- 5. Define Feature Sets for Two Models ---\n",
    "\n",
    "# Columns to look for in the encoded set:\n",
    "# Demographics: n_age_dv, female, n_hhsize, n_nchild_dv, marstat_final_, race_grp_, is_urban\n",
    "demographic_cols = [col for col in X_encoded.columns if any(c in col for c in \n",
    "    ['n_age_dv', 'female', 'n_hhsize', 'n_nchild_dv', 'marstat_final_', 'race_grp_', 'is_urban', 'financial_difficulty', 'has_disability'])]\n",
    "\n",
    "# Core features: is_currently_unemployed, education_level\n",
    "core_unemp_cols = [col for col in X_encoded.columns if 'is_currently_unemployed' == col]\n",
    "core_edu_cols = [col for col in X_encoded.columns if 'education_level' in col]\n",
    "\n",
    "# Model 1 Feature Set (Baseline)\n",
    "M1_FEATURES = list(set(demographic_cols + core_unemp_cols + core_edu_cols))\n",
    "M1_FEATURES = [f for f in M1_FEATURES if f in X_train_full.columns] # Filter out non-existent columns\n",
    "\n",
    "X_train_M1 = X_train_full[M1_FEATURES]\n",
    "X_test_M1 = X_test_full[M1_FEATURES]\n",
    "M1_feature_count = len(M1_FEATURES)\n",
    "\n",
    "# Model 2 Feature Set (Augmented - All Features)\n",
    "M2_FEATURES = X_train_full.columns.tolist()\n",
    "X_train_M2 = X_train_full\n",
    "X_test_M2 = X_test_full\n",
    "M2_feature_count = len(M2_FEATURES)\n",
    "\n",
    "print(f\"\\nModel 1 (Baseline) feature count: {M1_feature_count}\")\n",
    "print(f\"Model 2 (Augmented) feature count: {M2_feature_count}\")\n",
    "\n",
    "# --- 6. Feature Scaling (All Models) ---\n",
    "scaler = StandardScaler()\n",
    "X_train_M1_scaled = scaler.fit_transform(X_train_M1)\n",
    "X_test_M1_scaled = scaler.transform(X_test_M1)\n",
    "\n",
    "# Fit a new scaler instance for Model 2 (since the feature sets are different)\n",
    "scaler = StandardScaler()\n",
    "X_train_M2_scaled = scaler.fit_transform(X_train_M2)\n",
    "X_test_M2_scaled = scaler.transform(X_test_M2)\n",
    "\n",
    "# --- 7. Train and Evaluate Model 1 (Baseline) ---\n",
    "\n",
    "# Using 'balanced' class weights to handle class imbalance\n",
    "M1_model = LogisticRegression(\n",
    "    random_state=42, \n",
    "    class_weight='balanced', \n",
    "    solver='liblinear',\n",
    "    C=1.0, \n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "print(\"\\n--- Training Model 1 (Baseline: Core Unemp + Core Edu + Demographics) ---\")\n",
    "M1_model.fit(X_train_M1_scaled, y_train)\n",
    "\n",
    "y_pred_M1 = M1_model.predict(X_test_M1_scaled)\n",
    "y_proba_M1 = M1_model.predict_proba(X_test_M1_scaled)[:, 1]\n",
    "\n",
    "roc_auc_M1 = roc_auc_score(y_test, y_proba_M1)\n",
    "\n",
    "print(f\"Model 1 ROC AUC Score: {roc_auc_M1:.4f}\")\n",
    "print(\"Classification Report M1:\")\n",
    "print(classification_report(y_test, y_pred_M1))\n",
    "\n",
    "# --- 8. Train and Evaluate Model 2 (Augmented) ---\n",
    "\n",
    "# Using 'balanced' class weights\n",
    "M2_model = LogisticRegression(\n",
    "    random_state=42, \n",
    "    class_weight='balanced', \n",
    "    solver='liblinear',\n",
    "    C=1.0, \n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "print(\"\\n--- Training Model 2 (Augmented: All Features) ---\")\n",
    "M2_model.fit(X_train_M2_scaled, y_train)\n",
    "\n",
    "y_pred_M2 = M2_model.predict(X_test_M2_scaled)\n",
    "y_proba_M2 = M2_model.predict_proba(X_test_M2_scaled)[:, 1]\n",
    "\n",
    "roc_auc_M2 = roc_auc_score(y_test, y_proba_M2)\n",
    "\n",
    "print(f\"Model 2 ROC AUC Score: {roc_auc_M2:.4f}\")\n",
    "print(\"Classification Report M2:\")\n",
    "print(classification_report(y_test, y_pred_M2))\n",
    "\n",
    "# --- 9. Summary and Comparison ---\n",
    "\n",
    "print(\"\\n--- Model Comparison Summary (GHQ-12 Distress Classification) ---\")\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': ['Model 1 (Baseline)', 'Model 2 (Augmented)'],\n",
    "    'Features': [M1_feature_count, M2_feature_count],\n",
    "    'ROC AUC Score': [roc_auc_M1, roc_auc_M2]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(comparison_df.to_markdown(index=False, numalign=\"left\", stralign=\"left\", floatfmt=\".4f\"))\n",
    "\n",
    "# Detailed Analysis of Core Coefficients (Model 1)\n",
    "coefficients_M1 = pd.Series(M1_model.coef_[0], index=X_train_M1.columns)\n",
    "top_10_features_M1 = coefficients_M1.abs().sort_values(ascending=False).head(10).index.tolist()\n",
    "\n",
    "print(\"\\nTop 10 Most Influential Features (Coefficients) for Model 1:\")\n",
    "print(coefficients_M1.loc[top_10_features_M1].sort_values(ascending=False).to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6077af8a-89e5-4a28-9789-82e9d23fc531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting GridSearchCV for Model 2 (Augmented) with 5-Fold CV...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "--- Hyperparameter Tuning Results (Model 2) ---\n",
      "Best Parameters: {'C': 0.01, 'penalty': 'l1'}\n",
      "Best CV ROC AUC Score: 0.6778\n",
      "Test Set ROC AUC Score (Tuned Model): 0.7334\n",
      "\n",
      "Classification Report (Tuned Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79      5356\n",
      "           1       0.38      0.61      0.47      1467\n",
      "\n",
      "    accuracy                           0.70      6823\n",
      "   macro avg       0.62      0.67      0.63      6823\n",
      "weighted avg       0.77      0.70      0.72      6823\n",
      "\n",
      "\n",
      "Number of Features Selected by L1: 94 out of 251\n",
      "\n",
      "Top 10 Most Influential Features (Coefficients) for Tuned Model (l1):\n",
      "|                         | 0          |\n",
      "|:------------------------|:-----------|\n",
      "| has_disability          | 0.43185    |\n",
      "| financial_difficulty    | 0.337458   |\n",
      "| finfut_2.0              | 0.273781   |\n",
      "| female                  | 0.183813   |\n",
      "| inactive_lt_sick        | 0.166663   |\n",
      "| actively_seeking        | 0.146465   |\n",
      "| marginally_attached     | 0.104883   |\n",
      "| is_currently_unemployed | 0.0419233  |\n",
      "| marstat_final_2.1       | -0.0856281 |\n",
      "| n_age_dv                | -0.305381  |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "# Load the full feature set (X_encoded) and the binary target (y) from the previous step's logic\n",
    "\n",
    "file_path = \"/Users/wanderer/Thesis/ModelProject/Processed_Data/n_indresp_FINAL_FEATURES_OPTIMIZED.csv\"\n",
    "TARGET_CONT_COL = 'ghq12_continuous_score'\n",
    "TARGET_BIN_COL = 'ghq12_distress'\n",
    "GHQ12_THRESHOLD = 4\n",
    "\n",
    "def make_columns_unique(df):\n",
    "    cols = df.columns\n",
    "    seen = {}\n",
    "    new_cols = []\n",
    "    for item in cols:\n",
    "        original_name = item\n",
    "        count = seen.get(original_name, 0)\n",
    "        if count == 0:\n",
    "            new_cols.append(original_name)\n",
    "        else:\n",
    "            new_cols.append(f\"{original_name}_{count}\")\n",
    "        seen[original_name] = count + 1\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = make_columns_unique(df)\n",
    "except FileNotFoundError:\n",
    "    raise\n",
    "\n",
    "# Target Transformation and Filtering\n",
    "df = df.dropna(subset=[TARGET_CONT_COL]).copy()\n",
    "df = df[df[TARGET_CONT_COL] >= 0].copy()\n",
    "df[TARGET_BIN_COL] = (df[TARGET_CONT_COL] >= GHQ12_THRESHOLD).astype(int)\n",
    "\n",
    "# Feature Preparation (Full X_encoded)\n",
    "drop_cols = ['pidp', 'mental_health_status', TARGET_CONT_COL, TARGET_BIN_COL, 'has_mh_issue']\n",
    "X = df.drop(columns=[col for col in drop_cols if col in df.columns], errors='ignore')\n",
    "y = df[TARGET_BIN_COL]\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "\n",
    "unemp_impute_zero = ['last_unemployment_duration_months', 'subjective_job_chance_likely', 'unemployment_spells_count']\n",
    "for col in unemp_impute_zero:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].fillna(0)\n",
    "\n",
    "numerical_to_impute = [col for col in numerical_cols if col not in unemp_impute_zero]\n",
    "for col in numerical_to_impute:\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].fillna(X[col].mode()[0])\n",
    "\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "X_full = X_encoded.copy()\n",
    "\n",
    "\n",
    "# --- 2. Train-Test Split (Re-split for full consistency) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_full, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- 3. Feature Scaling ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "\n",
    "\n",
    "# --- 4. Hyperparameter Tuning (Model 2: Augmented) ---\n",
    "\n",
    "# Define the search space for the regularization parameter C (inverse of regularization strength)\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'] # Test both L1 (LASSO) and L2 (Ridge)\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "log_reg_base = LogisticRegression(\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    solver='liblinear', # Supports both l1 and l2\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "# Define ROC AUC as the scoring metric\n",
    "scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=5,                 # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1             # Use all available cores\n",
    ")\n",
    "\n",
    "print(\"\\nStarting GridSearchCV for Model 2 (Augmented) with 5-Fold CV...\")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- 5. Evaluate Best Model ---\n",
    "best_model = grid_search.best_estimator_\n",
    "y_proba_tuned = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred_tuned = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Final Metrics\n",
    "roc_auc_tuned = roc_auc_score(y_test, y_proba_tuned)\n",
    "\n",
    "print(\"\\n--- Hyperparameter Tuning Results (Model 2) ---\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV ROC AUC Score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Test Set ROC AUC Score (Tuned Model): {roc_auc_tuned:.4f}\")\n",
    "print(\"\\nClassification Report (Tuned Model):\")\n",
    "print(classification_report(y_test, y_pred_tuned))\n",
    "\n",
    "# --- 6. Feature Importance (Best Model) ---\n",
    "coefficients_tuned = pd.Series(best_model.coef_[0], index=X_train.columns)\n",
    "# Filter for non-zero coefficients if L1 was chosen, or top 10 if L2\n",
    "if best_model.penalty == 'l1':\n",
    "    selected_features = coefficients_tuned[coefficients_tuned != 0]\n",
    "    print(f\"\\nNumber of Features Selected by L1: {len(selected_features)} out of {X_train.shape[1]}\")\n",
    "    top_features = selected_features.abs().sort_values(ascending=False).head(10).index.tolist()\n",
    "else:\n",
    "    top_features = coefficients_tuned.abs().sort_values(ascending=False).head(10).index.tolist()\n",
    "\n",
    "print(f\"\\nTop 10 Most Influential Features (Coefficients) for Tuned Model ({best_model.penalty}):\")\n",
    "print(coefficients_tuned.loc[top_features].sort_values(ascending=False).to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8042ddd0-311d-4f4e-80a3-aaf803b78354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Scikit-learn Gradient Boosting Classifier (with Sample Weights)...\n",
      "\n",
      "--- Model Evaluation: GradientBoostingClassifier ---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79      5356\n",
      "           1       0.38      0.62      0.47      1467\n",
      "\n",
      "    accuracy                           0.70      6823\n",
      "   macro avg       0.62      0.67      0.63      6823\n",
      "weighted avg       0.77      0.70      0.72      6823\n",
      "\n",
      "ROC AUC Score: 0.7333\n",
      "\n",
      "Confusion Matrix:\n",
      "|          | Predicted 0   | Predicted 1   |\n",
      "|:---------|:--------------|:--------------|\n",
      "| Actual 0 | 3831          | 1525          |\n",
      "| Actual 1 | 552           | 915           |\n",
      "\n",
      "Top 10 Most Important Features (GBM Importance):\n",
      "|                      | 0         |\n",
      "|:---------------------|:----------|\n",
      "| financial_difficulty | 0.274773  |\n",
      "| has_disability       | 0.191956  |\n",
      "| n_age_dv             | 0.14876   |\n",
      "| female               | 0.0438439 |\n",
      "| actively_seeking     | 0.0355436 |\n",
      "| inactive_lt_sick     | 0.0341094 |\n",
      "| finfut_2.0           | 0.0326289 |\n",
      "| marginally_attached  | 0.0244026 |\n",
      "| finfut_2.1           | 0.0229722 |\n",
      "| n_hhsize             | 0.021185  |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0. Define Constants \n",
    "FILE_PATH = \"/Users/wanderer/Thesis/ModelProject/Processed_Data/n_indresp_FINAL_FEATURES_OPTIMIZED.csv\"\n",
    "RANDOM_SEED = 42\n",
    "GHQ12_THRESHOLD = 4\n",
    "TARGET_CONT_COL = 'ghq12_continuous_score'\n",
    "TARGET_BIN_COL = 'ghq12_distress'\n",
    "\n",
    "# 1. Load and Prepare Data (Re-run preparation logic to ensure data integrity) \n",
    "\n",
    "def make_columns_unique(df):\n",
    "    \"\"\"Makes column names unique by appending a counter to duplicates.\"\"\"\n",
    "    cols = df.columns\n",
    "    seen = {}\n",
    "    new_cols = []\n",
    "    for item in cols:\n",
    "        original_name = item\n",
    "        count = seen.get(original_name, 0)\n",
    "        if count == 0:\n",
    "            new_cols.append(original_name)\n",
    "        else:\n",
    "            new_cols.append(f\"{original_name}_{count}\")\n",
    "        seen[original_name] = count + 1\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "# Load Data\n",
    "try:\n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "    df = make_columns_unique(df)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at the specified path: {FILE_PATH}\")\n",
    "    raise\n",
    "\n",
    "# Target Transformation and Filtering\n",
    "df = df.dropna(subset=[TARGET_CONT_COL]).copy()\n",
    "df = df[df[TARGET_CONT_COL] >= 0].copy()\n",
    "df[TARGET_BIN_COL] = (df[TARGET_CONT_COL] >= GHQ12_THRESHOLD).astype(int)\n",
    "\n",
    "# Feature Preparation (Full X_encoded)\n",
    "drop_cols = ['pidp', 'mental_health_status', TARGET_CONT_COL, TARGET_BIN_COL, 'has_mh_issue']\n",
    "X = df.drop(columns=[col for col in drop_cols if col in df.columns], errors='ignore')\n",
    "y = df[TARGET_BIN_COL]\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "\n",
    "# Imputation\n",
    "unemp_impute_zero = ['last_unemployment_duration_months', 'subjective_job_chance_likely', 'unemployment_spells_count']\n",
    "for col in unemp_impute_zero:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].fillna(0)\n",
    "\n",
    "numerical_to_impute = [col for col in numerical_cols if col not in unemp_impute_zero]\n",
    "for col in numerical_to_impute:\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].fillna(X[col].mode()[0])\n",
    "\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "X_full = X_encoded.copy()\n",
    "\n",
    "\n",
    "# Train-Test Split (Augmented Feature Set - Model 2)\n",
    "# Re-split using the correct target and random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_full, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Calculate Sample Weights for Class Imbalance ---\n",
    "\n",
    "# Calculate weights based on the inverse frequency of each class in the training set\n",
    "weight_minority = 1.0 / np.sum(y_train == 1)\n",
    "weight_majority = 1.0 / np.sum(y_train == 0)\n",
    "\n",
    "# Assign weights to each sample\n",
    "sample_weights = np.where(y_train == 1, weight_minority, weight_majority)\n",
    "# Normalize weights\n",
    "sample_weights = sample_weights / sample_weights.sum() * len(y_train)\n",
    "\n",
    "\n",
    "# 3. Train GradientBoostingClassifier \n",
    "\n",
    "gbm_clf = GradientBoostingClassifier(\n",
    "    n_estimators=300,          # Increased \n",
    "    learning_rate=0.03,        # Slower \n",
    "    max_depth=4,               # Tree depth\n",
    "    subsample=0.8,             # Subsampling\n",
    "    random_state=RANDOM_SEED   \n",
    ")\n",
    "\n",
    "print(\"\\nTraining Scikit-learn Gradient Boosting Classifier (with Sample Weights)...\")\n",
    "# Fit the model using sample weights to account for the imbalanced target\n",
    "gbm_clf.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# 4. Evaluate Model \n",
    "y_pred_gbm = gbm_clf.predict(X_test)\n",
    "y_proba_gbm = gbm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n--- Model Evaluation: GradientBoostingClassifier ---\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gbm))\n",
    "\n",
    "# ROC AUC Score\n",
    "roc_auc_gbm = roc_auc_score(y_test, y_proba_gbm)\n",
    "print(f\"ROC AUC Score: {roc_auc_gbm:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_gbm = confusion_matrix(y_test, y_pred_gbm)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(cm_gbm, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1']).to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# 5. Feature Importance \n",
    "feature_importance_gbm = pd.Series(gbm_clf.feature_importances_, index=X_train.columns)\n",
    "\n",
    "# Select the top 10 most important features\n",
    "top_10_features_gbm = feature_importance_gbm.sort_values(ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features (GBM Importance):\")\n",
    "print(top_10_features_gbm.to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd09855-54d5-4b26-949f-0caad6c650c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
