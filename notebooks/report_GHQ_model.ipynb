{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be026b8",
   "metadata": {},
   "source": [
    "# ğŸ“‹ æ¨¡å‹é¢„æµ‹æŠ¥å‘Šï¼šGHQå¿ƒç†å¥åº·é¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e87db13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–ç¯å¢ƒä¸è·¯å¾„é…ç½®\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from utils.config import load_config, abspath\n",
    "cfg, root = load_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0239821",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/wanderer/DSS_Thesis/report/predictions/baseline_predictions.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m preds_path \u001b[38;5;241m=\u001b[39m abspath(root, cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodeling\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions_file\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m metrics_path \u001b[38;5;241m=\u001b[39m abspath(root, cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodeling\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics_file\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m df_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(preds_path)\n\u001b[1;32m      6\u001b[0m metrics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(metrics_path)\n\u001b[1;32m      7\u001b[0m metrics\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    668\u001b[0m     path,\n\u001b[1;32m    669\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m    670\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[1;32m    671\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    672\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[1;32m    673\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    674\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    676\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    268\u001b[0m     path,\n\u001b[1;32m    269\u001b[0m     filesystem,\n\u001b[1;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m    141\u001b[0m         path_or_handle, mode, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/wanderer/DSS_Thesis/report/predictions/baseline_predictions.parquet'"
     ]
    }
   ],
   "source": [
    "# åŠ è½½æ¨¡å‹é¢„æµ‹ä¸æŒ‡æ ‡\n",
    "preds_path = abspath(root, cfg[\"modeling\"][\"outputs\"][\"predictions_file\"])\n",
    "metrics_path = abspath(root, cfg[\"modeling\"][\"outputs\"][\"metrics_file\"])\n",
    "\n",
    "df_pred = pd.read_parquet(preds_path)\n",
    "metrics = pd.read_json(metrics_path)\n",
    "metrics.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d92c8a6",
   "metadata": {},
   "source": [
    "## ğŸ¯ ç›®æ ‡å˜é‡åˆ†å¸ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç›®æ ‡å˜é‡åˆ†å¸ƒå›¾\n",
    "sns.countplot(data=df_pred, x=\"target_cls\")\n",
    "plt.title(\"GHQ Caseness æ ‡ç­¾åˆ†å¸ƒ\")\n",
    "plt.xlabel(\"GHQ â‰¥ 4 æ˜¯å¦å¿ƒç†å›°æ‰°\")\n",
    "plt.ylabel(\"æ ·æœ¬æ•°\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bd87d8",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ¨¡å‹æ··æ·†çŸ©é˜µä¸å‡†ç¡®ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94398360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(df_pred[\"target_cls\"], df_pred[\"y_pred\"])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848a304e",
   "metadata": {},
   "source": [
    "## ğŸ§  ç‰¹å¾é‡è¦æ€§ï¼ˆè‹¥é€‚ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e560a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¤ºä¾‹ä»£ç ï¼ˆå¦‚ä½¿ç”¨åŸºäº coef_ æˆ– feature_importances_ çš„æ¨¡å‹ï¼‰\n",
    "try:\n",
    "    model_path = abspath(root, cfg[\"modeling\"][\"outputs\"][\"model_file\"])\n",
    "    import joblib\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    importances = None\n",
    "    if hasattr(model, \"coef_\"):\n",
    "        importances = model.coef_[0]\n",
    "    elif hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "\n",
    "    if importances is not None:\n",
    "        features = df_pred.drop(columns=[\"target_cls\", \"y_pred\", \"y_proba\"]).columns\n",
    "        fi_df = pd.DataFrame({\"feature\": features, \"importance\": importances})\n",
    "        fi_df = fi_df.sort_values(\"importance\", ascending=False).head(20)\n",
    "\n",
    "        sns.barplot(data=fi_df, x=\"importance\", y=\"feature\")\n",
    "        plt.title(\"Top 20 ç‰¹å¾é‡è¦æ€§\")\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print(\"æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§å¯è§†åŒ–:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
